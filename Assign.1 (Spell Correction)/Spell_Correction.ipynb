{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Spell COrrection\n",
    "\n",
    "### Import essential package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet #dictionnary D\n",
    "import pytrec_eval\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Edit Distance Algorithm\n",
    "\n",
    "In this part, we worked on implementing and testing the Mininum Edit Distance Algorithm (MED)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MED(source, target):\n",
    "    s = len(source)\n",
    "    t = len(target)\n",
    "    del_cost = 1\n",
    "    ins_cost = 1\n",
    "    sub_cost = 0\n",
    "    distance = np.zeros((s+1, t+1))\n",
    "\n",
    "    for i in range(1, s+1):\n",
    "        distance[i,0] = i\n",
    "    for j in range(1,t+1):\n",
    "        distance[0,j] = j\n",
    "\n",
    "    for i in range(1, s+1):\n",
    "        for j in range(1, t+1):\n",
    "            func1 = distance[i, j-1]\n",
    "            func2 = distance[i-1, j]\n",
    "            func3 = distance[i-1, j-1]\n",
    "\n",
    "            if source[i-1] == target[j-1]:\n",
    "                sub_cost = 0\n",
    "            else:\n",
    "                sub_cost = 2\n",
    "            \n",
    "            if func1 <= func2 and func1 <= func3:\n",
    "                distance[i, j] = func1 + ins_cost\n",
    "            elif func2 <= func1 and func2 <= func3:\n",
    "                distance[i, j] = func2 + del_cost\n",
    "            else:\n",
    "                distance[i, j] = func3 + sub_cost\n",
    "\n",
    "    return distance[s, t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the top-k (most similar, least distant) list of tokens\n",
    "\n",
    "In this part, we worked on implementing the algorithms to find the top-k (most similar, least distant) list of tokens that are retrieved by the MED from wordnet. \n",
    "\n",
    "1. The first algorithm, find_nearst_token(token), will take the incorrect spell and return the list of all similar tokens in the WordNet dictionary.\n",
    "2. The second algorithm, find_top_k(nearest_token, k), aim to reduce to the list of all similar tokens above and return the list only k numbers of token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\?'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\?'\n",
      "C:\\Users\\duong\\AppData\\Local\\Temp\\ipykernel_8740\\1798278232.py:2: SyntaxWarning: invalid escape sequence '\\?'\n",
      "  special_char = '|!@#$%^&*()_-=+,.<>/\\?;:~`1234567890'\n"
     ]
    }
   ],
   "source": [
    "def find_nearest_token(token):\n",
    "    special_char = '|!@#$%^&*()_-=+,.<>/\\?;:~`1234567890'\n",
    "    words = [w for w in wordnet.all_lemma_names()\n",
    "        if len([c for c in list(token) if c in list(w)]) > 0 and not any (c in special_char for c in w)]\n",
    "    nearest_token = sorted([(MED(token, w), w) for w in words], key=lambda n:n[0])\n",
    "    return nearest_token\n",
    "\n",
    "def find_top_k (nearest_token, k):\n",
    "    length = len(nearest_token) - 1 \n",
    "    while length > k:\n",
    "        nearest_token.pop(length)\n",
    "        length -= 1\n",
    "    return nearest_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create two lists, correct and incorrect words\n",
    "\n",
    "The two lists, correct and incorrect words, aim to store the data imported from the Data folder\n",
    "* In this algorithm, we will be using the 'APPLING2DAT.643' and 'UPWARDDAT.643' data sets downloaded from BirkBeck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Words list ['visited', 'magnificent', 'opposite', 'gallery', 'splendid', 'purple']\n",
      "Incorrect Words list ['visit', 'magnefision', 'aposit', 'galleroy', 'spenlid', 'purpal']\n"
     ]
    }
   ],
   "source": [
    "corpus = open('Data/APPLING2DAT.643', 'r')\n",
    "line = 0\n",
    "corpus_list = []\n",
    "correct_word = []\n",
    "incorrect_word = []\n",
    "\n",
    "while line <= 5:\n",
    "    read_string = corpus.readline()\n",
    "    temp_string = read_string.replace('\\n', '')\n",
    "    string = temp_string.split(\" \")\n",
    "    corpus_list.append(string)\n",
    "    line += 1\n",
    "\n",
    "for i in range(len(corpus_list)):\n",
    "    correct_word.append(corpus_list[i][1])\n",
    "    incorrect_word.append(corpus_list[i][0])\n",
    "\n",
    "print('Correct Words list', correct_word)\n",
    "print('Incorrect Words list', incorrect_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the average s@k for k={1, 5, 10}\n",
    "\n",
    "This part includes the main algorithm to find the the average s@k for k={1, 5, 10}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited\n",
      "s@k for k = 1:  0.0\n",
      "s@k for k = 5:  0.0\n",
      "s@k for k = 10:  0.0\n",
      "magnificent\n",
      "s@k for k = 1:  0.0\n",
      "s@k for k = 5:  0.0\n",
      "s@k for k = 10:  0.0\n",
      "opposite\n",
      "s@k for k = 1:  0.0\n",
      "s@k for k = 5:  0.0\n",
      "s@k for k = 10:  0.0\n",
      "gallery\n",
      "s@k for k = 1:  0.15789473684210525\n",
      "s@k for k = 5:  0.0\n",
      "s@k for k = 10:  0.0\n",
      "splendid\n",
      "s@k for k = 1:  0.0\n",
      "s@k for k = 5:  0.0\n",
      "s@k for k = 10:  0.0\n",
      "purple\n",
      "s@k for k = 1:  0.0\n",
      "s@k for k = 5:  0.0\n",
      "s@k for k = 10:  0.0\n"
     ]
    }
   ],
   "source": [
    "for c in range(len(correct_word))  :\n",
    "    correct_spell = correct_word[c]\n",
    "    print(correct_spell)\n",
    "    incorrect_spell = incorrect_word[c]\n",
    "    checked_token = []\n",
    "    s1_list = []\n",
    "    s5_list = []\n",
    "    s10_list = []\n",
    "    count = 0\n",
    "\n",
    "    for k in [1, 5, 10]:\n",
    "        temp_list = find_nearest_token(incorrect_spell)\n",
    "        checked_token = find_top_k(temp_list, k)       \n",
    "        for i in range(len(checked_token)):\n",
    "            count += 1\n",
    "            if checked_token[i][1] == correct_spell:\n",
    "                if  i == 0:\n",
    "                    s1_list.append(checked_token[i][0])\n",
    "                elif i == 4:\n",
    "                    s5_list.append(checked_token[i][0])\n",
    "                elif i == 9:\n",
    "                    s10_list.append(checked_token[i][0])\n",
    "            else:\n",
    "                s1_list.append(0)\n",
    "                s5_list.append(0)\n",
    "                s10_list.append(0)\n",
    "\n",
    "    print(\"s@k for k = 1: \", pytrec_eval.compute_aggregated_measure('gm',s1_list))\n",
    "    print(\"s@k for k = 5: \", pytrec_eval.compute_aggregated_measure(\"gm\", s5_list))\n",
    "    print(\"s@k for k = 10: \", pytrec_eval.compute_aggregated_measure(\"gm\", s10_list))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
